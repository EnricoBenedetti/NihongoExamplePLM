{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from utils import *\n",
    "\n",
    "import gspread\n",
    "import gspread_formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_evaluation_file(content):\n",
    "    # Split the content into systems\n",
    "    system_blocks = re.split(r'\\n(?=System \\d sentences:)', content)\n",
    "    \n",
    "    parsed_data = {}\n",
    "    \n",
    "    for block in system_blocks:\n",
    "        # Extract system name\n",
    "        system_name_match = re.search(r'(System \\d) sentences:', block)\n",
    "        if system_name_match:\n",
    "            system_name = system_name_match.group(1)\n",
    "            parsed_data[system_name] = {'sentences': [], 'sentence_diversity': '', 'comment': ''}\n",
    "            \n",
    "            # Extract sentences\n",
    "            sentences = re.findall(r'\\d+\\.\\sDifficulty:\\s\"?(.*?)\"?;\\sSense:\\s\"?(.*?)\"?;\\sReject:\\s\"?(.*?)\"?', block)\n",
    "            for difficulty, sense, reject in sentences:\n",
    "                parsed_data[system_name]['sentences'].append({\n",
    "                    'difficulty': difficulty,\n",
    "                    'sense': sense.capitalize(),\n",
    "                    'reject': reject\n",
    "                })\n",
    "            \n",
    "            # Extract sentence diversity\n",
    "            diversity_match = re.search(r'Sentence diversity: \"?(.*?)\"?', block)\n",
    "            if diversity_match:\n",
    "                parsed_data[system_name]['sentence_diversity'] = diversity_match.group(1)\n",
    "    \n",
    "    # Extract system ranking\n",
    "    ranking_match = re.search(r'System ranking: (.*)', content)\n",
    "    if ranking_match:\n",
    "        parsed_data['system_ranking'] = ranking_match.group(1)\n",
    "    \n",
    "    # Extract comments, assuming they always appear at the end and start with \"Comment:\"\n",
    "    comment_match = re.search(r'Comment: (.*)', content, re.DOTALL)\n",
    "    if comment_match:\n",
    "        parsed_data['comment'] = comment_match.group(1).strip()\n",
    "    \n",
    "    return parsed_data\n",
    "\n",
    "def update_cells_gpt(content, sheet):\n",
    "    gpt_resps = content.split(sep='Comment:')[:3]\n",
    "    resp_numbers = [0,1,2]\n",
    "    # resp_number = 0 # which gpt response\n",
    "    for resp_number in resp_numbers:\n",
    "        offset = 20*resp_number\n",
    "        data = []\n",
    "        parse = parse_evaluation_file(gpt_resps[resp_number])\n",
    "        ranking = parse['system_ranking']\n",
    "        data += [{'range': f'A{34+offset}', 'values': [[ranking]]}]\n",
    "        for sys_id in [1,2,3]:\n",
    "            # get diff labels for sys 1\n",
    "            l = parse[f'System {sys_id}']['sentences']\n",
    "            diff_labels = [x['difficulty'] for x in l]\n",
    "            sense_labels = [x['sense'] for x in l]\n",
    "            reject_labels = [x['reject'] for x in l]\n",
    "            diversity = parse[f'System {sys_id}']['sentence_diversity']\n",
    "            \n",
    "            letter_diff = chr(ord('B') + 4*(sys_id-1))\n",
    "            letter_sense = chr(ord('C') + 4*(sys_id-1))\n",
    "            letter_reject = chr(ord('D') + 4*(sys_id-1))\n",
    "            letter_diversity = chr(ord('A') + 4*(sys_id-1))\n",
    "            data += [{'range': f'{letter_diff}{25+offset}:{letter_diff}{29+offset}', 'values': [diff_labels], 'major_dimension' : 'COLUMNS'},\n",
    "                    {'range': f'{letter_sense}{25+offset}:{letter_sense}{29+offset}', 'values': [sense_labels], 'major_dimension' : 'COLUMNS'},\n",
    "                    {'range': f'{letter_reject}{25+offset}:{letter_reject}{29+offset}', 'values': [reject_labels], 'major_dimension' : 'COLUMNS'},\n",
    "                    {'range': f'{letter_diversity}{31+offset}', 'values': [[diversity]]}]\n",
    "        sheet.batch_update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.service_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.open(\"Evaluation-sheet-jp-v3.0_gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = sh.worksheet(\"14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the block under it starting form row 21\n",
    "for sheet_number in range(16,26):\n",
    "    sheet = sh.worksheet(f\"{sheet_number}\")\n",
    "    block_start_cells = ['A21', 'A41', 'A61']\n",
    "    for dest_cell in block_start_cells:\n",
    "        sheet.copy_range(source=\"A1:L13\", dest=dest_cell, paste_type='PASTE_NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_id = 14\n",
    "file_name = f\"/data/enrico_benedetti/nihongoexample/evaluation/annotation/gpt/short_responses/gpt-4-0125-preview_{block_id}.txt\"\n",
    "\n",
    "content = \"\"\n",
    "with open(file_name, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "parse = parse_evaluation_file(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It still needs to fix it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_number in range(16,26):\n",
    "    sheet = sh.worksheet(f\"{sheet_number}\")\n",
    "    block_id = sheet_number\n",
    "    file_name = f\"/data/enrico_benedetti/nihongoexample/evaluation/annotation/gpt/short_responses/gpt-4-0125-preview_{block_id}.txt\"\n",
    "    content = \"\"\n",
    "    \n",
    "    with open(file_name, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    update_cells_gpt(content, sheet)\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
