{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['する記号である。']\n",
      "['」を意味する記号である。']\n",
      "['の合字を起源とする。']\n",
      "['の合字であることが容易にわかる字形を使用している。']\n",
      "['のように唱えられていた。']\n",
      "['を加えることも広く行われていた。']\n",
      "['と読まれるようになった。']\n",
      "['という形になった。']\n",
      "['年までには英語の一般的な語法となった。']\n",
      "['と呼ばれるようになったという誤った語源俗説がある。']\n",
      "['世紀の古ローマ筆記体にまでさかのぼることができる。']\n",
      "['。それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。']\n",
      "['の合字の例である。']\n",
      "['世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れていった。']\n",
      "['の合字にさかのぼる。']\n",
      "['年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアンパサンドの両方を多用するようになった。']\n",
      "['アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語でアンパサンドが使用されるようになった。']\n",
      "['アンパサンドはしばしばラテンアルファベットの最後の文字とされることがあった。']\n",
      "['年のの文字表がその例である。']\n",
      "['番目の文字とされ、アメリカ合衆国やその他の地域でも、子供達はアンパサンドはアルファベットの最後の文字だと教えられていた。']\n",
      "['にその一例を見ることができる。']\n",
      "['に次のセリフを語らせている。']\n",
      "['という歌詞で締めくくられる。']\n",
      "['とは別のものである。']\n",
      "['」に似た形の記号である。']\n",
      "['を表すために使用された。']\n",
      "['はそれぞれ独立に発明されたものである。']\n",
      "['が使用されていた。']\n",
      "['今日はゲール文字の一部として主に装飾的な目的で使用されている。']\n",
      "['この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。']\n",
      "['に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。']\n",
      "['また、エプシロンの上下に縦線または点を付けたものもしばしば使われる。']\n",
      "['がアンパサンドの代わりに使われることがある。']\n",
      "['また、プラス記号に輪を重ねたような、無声歯茎側面摩擦音を示す発音記号「」のようなものが使われることもある。']\n",
      "['がある。']\n",
      "['この文字はドイツのフラクトゥールで使われたほか、ゲール文字でも使用される。']\n",
      "['が使われることがある。']\n",
      "['演算子として用いられる。']\n",
      "['の例。']\n",
      "['の直前に記述することで、参照渡しを行うことができる。']\n",
      "['系列の言語では文字列の連結演算子として使用される。']\n",
      "['を返す。']\n",
      "['のように表現する。']\n",
      "['実体を参照する。']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "# Updated regular expression pattern for full Japanese sentences\n",
    "pattern = r'(?<!「|『)[\\u3000-\\u303F\\u4E00-\\u9FAF\\u3040-\\u309F\\u30A0-\\u30FF、\\n]+?[。？！](?!」|』)'\n",
    "#pattern = r'(?<![\\r\\n。！？])([。！？])(?![\\r\\n])'\n",
    "\n",
    "# Create the tokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "# Example Japanese text\n",
    "text = \"\"\"…」を意味.....,,,,,,,.する記号である。アンパサンド（&amp;, ）は、並立助詞「…と…」を意味する記号である。ラテン語で「…と…」を表す接続詞 \"et\" の合字を起源とする。現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" の合字であることが容易にわかる字形を使用している。語源.英語で教育を行う学校でアルファベットを復唱する場合、その文字自体が単語となる文字（\"A\", \"I\", かつては \" も）については、伝統的にラテン語の \"（それ自体）を用いて \"A per se A\" のように唱えられていた。また、アルファベットの最後に、27番目の文字のように \"&amp;\" を加えることも広く行われていた。\"&amp;\" はラテン語で \"et\" と読まれていたが、のちに英語で \"and\" と読まれるようになった。結果として、アルファベットの復唱の最後は \"X, Y, Z, \"and per se and\"\" という形になった。この最後のフレーズが繰り返されるうちに \"ampersand\" となまっていき、この言葉は1837年までには英語の一般的な語法となった。アンドレ＝マリ・アンペールがこの記号を自身の著作で使い、これが広く読まれたため、この記号が \"Ampère's and\" と呼ばれるようになったという誤った語源俗説がある。歴史.アンパサンドの起源は1世紀の古ローマ筆記体にまでさかのぼることができる。古ローマ筆記体では、E と T はしばしば合字として繋げて書かれていた（左図「アンパサンドの変遷」の字形1）。それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。字形2と3は4世紀中頃における et の合字の例である。その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れていった。しかし、et の合字は使われ続け、次第に元の文字がわかりにくい字形に変化していった（字形4から6）。現代のイタリック体のアンパサンドは、ルネサンス期に発展した筆記体での et の合字にさかのぼる。1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアンパサンドの両方を多用するようになった。アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語でアンパサンドが使用されるようになった。アンパサンドはしばしばラテンアルファベットの最後の文字とされることがあった。たとえば1011年のの文字表がその例である。同様に、\"&amp;\" は英語アルファベットの27番目の文字とされ、アメリカ合衆国やその他の地域でも、子供達はアンパサンドはアルファベットの最後の文字だと教えられていた。1863年の M. B. Moore の著書 \"The Dixie Primer, for the Little Folks\" にその一例を見ることができる。ジョージ・エリオットは、1859年に発表した小説「」の中で、Jacob Storey に次のセリフを語らせている。\"He thought it [Z] had only been put to finish off th' alphabet like; though ampusand would ha' done as well, for what he could see.\" よく知られた童謡の は \"X, Y, Z, and ampersand, All wished for a piece in hand\" という歌詞で締めくくられる。アンパサンドは、ティロ式記号の et (\"⁊\", Unicode U+204A) とは別のものである。ティロ式記号の et は、アンパサンドと意味は同じだが数字の「7」に似た形の記号である。両者はともに古代から使用され、中世を通してラテン語の \"et\" を表すために使用された。しかし、アンパサンドとティロ式記号の et はそれぞれ独立に発明されたものである。ラテン文字から発展した古アイルランド語の文字では、アイルランド語の \"agus\"（「…と…」）を表すためにティロ式記号の et が使用されていた。今日はゲール文字の一部として主に装飾的な目的で使用されている。この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。手書き.日常的な手書きの場合、欧米では小文字の （エプシロン）を大きくしたもの（あるいは数字の \"3\" の鏡文字）に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。また、エプシロンの上下に縦線または点を付けたものもしばしば使われる。くだけた用法として、プラス記号（\"+\", この記号もまた et の合字である）がアンパサンドの代わりに使われることがある。また、プラス記号に輪を重ねたような、無声歯茎側面摩擦音を示す発音記号「」のようなものが使われることもある。同様の記号.ティロの速記には「et」を表すための「」(U+204A Tironian sign et)がある。この文字はドイツのフラクトゥールで使われたほか、ゲール文字でも使用される。ギリシア文字では「……と」を意味するを表すための合字として「」(U+03D7 Greek kai symbol)が使われることがある。プログラミング言語.プログラミング言語では、C など多数の言語で AND 演算子として用いられる。以下は C の例。PHPでは、変数宣言記号（$）の直前に記述することで、参照渡しを行うことができる。BASIC 系列の言語では文字列の連結演算子として使用される。codice_4 は codice_5 を返す。また、主にマイクロソフト系では整数の十六進表記に codice_6 を用い、codice_7 （十進で15）のように表現する。SGML、XML、HTMLでは、アンパサンドを使ってSGML実体を参照する。\"\"\"\n",
    "# Tokenize text\n",
    "sents = tokenizer.tokenize(text)\n",
    "#print(sents)\n",
    "for sent in sents:\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(r'[\\n\\t]', '', sent)\n",
    "    print([sent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good(sentence, token_limit=50, punct_ratio=0.2, numeral_ratio=0.2, tokenizer=None):\n",
    "    \"\"\"Basic surface level requirements for sentence inclusion. requires spacy.\n",
    "    If a list of tokens is passed, the doc is retrieved.\n",
    "    If a sentence is passed, it will be tokenized if also the spacy tokenizer is passed, otherwise it will raise exception...\"\"\"\n",
    "    # based on english characters and urls\n",
    "    # based on having at least 5 tokens [sangawa paper] and ending in punctuation, and ending with a ADJ, VERB, AUX.\n",
    "    \n",
    "    if isinstance(sentence, list):\n",
    "        # retrieve the doc from a list of tokens\n",
    "        sentence = sentence[0].doc\n",
    "    elif isinstance(sentence, str):\n",
    "        sentence = tokenizer(sentence)\n",
    "\n",
    "    sentence_length = len(sentence) # in tokens!!\n",
    "    if sentence_length < 5 or sentence_length > token_limit:\n",
    "        # print('len')\n",
    "        return False\n",
    "    \n",
    "    if (sentence[-1].pos_ != 'PUNCT') or (sentence[-2].pos_ not in ['AUX', 'ADJ', 'VERB']):\n",
    "    # print('ending')\n",
    "        return False\n",
    "    # pattern = r'[a-zA-Z]|https?:\\/\\/\\S+'\n",
    "    # if re.search(pattern, sentence.text) is not None:\n",
    "    #     return False\n",
    "    \n",
    "    # no more than 20% punctuation or numerals\n",
    "    #punct_match = re.findall(r'[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_``{|}~…]', sentence.text)\n",
    "    #punct_count = len(punct_match)\n",
    "    # we do not consider the last\n",
    "    punct_count = sum([token.is_punct for token in sentence[0:-1]])\n",
    "    if punct_count / sentence_length > punct_ratio:\n",
    "        print('too much punct',sentence_length, punct_count, punct_count / sentence_length)\n",
    "        return False\n",
    "    \n",
    "    # num_match = re.findall(r'\\d', sentence.text)\n",
    "    # num_count = len(num_match)\n",
    "    num_count = sum([token.is_digit for token in sentence]) # digit actually means a full token of digits\n",
    "    if num_count / sentence_length > numeral_ratio:\n",
    "        print('too much num',sentence_length, punct_count, punct_count / sentence_length)\n",
    "        return False\n",
    "    # no text in other languages\n",
    "    if re.search(r'.*[A-Za-z].*', sentence.text):\n",
    "        # print('english')\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(spacy.prefer_gpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico_benedetti/anaconda3/envs/nlp_env/lib/python3.8/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'ja_ginza_electra' (5.1.3) was trained with spaCy v3.2.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('ja_ginza_electra', enable='')\n",
    "for p in nlp.pipeline:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f11e38a2080>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer',\n",
       "  <ginza_transformers.pipeline_component.TransformerCustom at 0x7f1171b46fa0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f1171b36ac0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f1171b02f40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f1171b36c80>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x7f1171b46d60>),\n",
       " ('compound_splitter',\n",
       "  <ginza.compound_splitter.CompoundSplitter at 0x7f1171afad30>),\n",
       " ('bunsetu_recognizer',\n",
       "  <ginza.bunsetu_recognizer.BunsetuRecognizer at 0x7f1171b54250>),\n",
       " ('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x7f11e38a2080>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': {'train': 'corpus/ja_ginza-ud-train.ne.rea.random_sents.spacy',\n",
       "  'dev': 'corpus/ja_ginza-ud-dev.ne.rea.random_sents.spacy',\n",
       "  'vectors': None,\n",
       "  'init_tok2vec': None},\n",
       " 'system': {'gpu_allocator': 'pytorch', 'seed': 0},\n",
       " 'nlp': {'lang': 'ja',\n",
       "  'pipeline': ['transformer',\n",
       "   'parser',\n",
       "   'attribute_ruler',\n",
       "   'ner',\n",
       "   'morphologizer',\n",
       "   'compound_splitter',\n",
       "   'bunsetu_recognizer',\n",
       "   'sentencizer'],\n",
       "  'batch_size': 128,\n",
       "  'disabled': ['transformer',\n",
       "   'parser',\n",
       "   'attribute_ruler',\n",
       "   'ner',\n",
       "   'morphologizer',\n",
       "   'compound_splitter',\n",
       "   'bunsetu_recognizer'],\n",
       "  'before_creation': None,\n",
       "  'after_creation': None,\n",
       "  'after_pipeline_creation': None,\n",
       "  'tokenizer': {'@tokenizers': 'spacy.ja.JapaneseTokenizer',\n",
       "   'split_mode': 'C'}},\n",
       " 'components': {'transformer': {'factory': 'transformer_custom',\n",
       "   'max_batch_items': 4096,\n",
       "   'model': {'@architectures': 'spacy-transformers.TransformerModel.v3',\n",
       "    'name': 'megagonlabs/transformers-ud-japanese-electra-base-ginza-510',\n",
       "    'mixed_precision': False,\n",
       "    'get_spans': {'@span_getters': 'spacy-transformers.strided_spans.v1',\n",
       "     'window': 128,\n",
       "     'stride': 96},\n",
       "    'grad_scaler_config': {},\n",
       "    'tokenizer_config': {'use_fast': False,\n",
       "     'tokenizer_class': 'sudachitra.tokenization_electra_sudachipy.ElectraSudachipyTokenizer',\n",
       "     'do_lower_case': False,\n",
       "     'do_word_tokenize': True,\n",
       "     'do_subword_tokenize': True,\n",
       "     'word_tokenizer_type': 'sudachipy',\n",
       "     'subword_tokenizer_type': 'wordpiece',\n",
       "     'word_form_type': 'dictionary_and_surface',\n",
       "     'sudachipy_kwargs': {'split_mode': 'A', 'dict_type': 'core'}},\n",
       "    'transformer_config': {}},\n",
       "   'set_extra_annotations': {'@annotation_setters': 'spacy-transformers.null_annotation_setter.v1'}},\n",
       "  'parser': {'factory': 'parser',\n",
       "   'learn_tokens': False,\n",
       "   'min_action_freq': 30,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'parser',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 128,\n",
       "    'maxout_pieces': 3,\n",
       "    'use_upper': False,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1',\n",
       "     'grad_factor': 1.0,\n",
       "     'pooling': {'@layers': 'reduce_mean.v1'},\n",
       "     'upstream': '*'}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.parser_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100},\n",
       "  'attribute_ruler': {'factory': 'attribute_ruler',\n",
       "   'scorer': {'@scorers': 'spacy.attribute_ruler_scorer.v1'},\n",
       "   'validate': False},\n",
       "  'ner': {'factory': 'ner',\n",
       "   'incorrect_spans_key': None,\n",
       "   'model': {'@architectures': 'spacy.TransitionBasedParser.v2',\n",
       "    'state_type': 'ner',\n",
       "    'extra_state_tokens': False,\n",
       "    'hidden_width': 64,\n",
       "    'maxout_pieces': 2,\n",
       "    'use_upper': False,\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1',\n",
       "     'grad_factor': 1.0,\n",
       "     'pooling': {'@layers': 'reduce_mean.v1'},\n",
       "     'upstream': '*'}},\n",
       "   'moves': None,\n",
       "   'scorer': {'@scorers': 'spacy.ner_scorer.v1'},\n",
       "   'update_with_oracle_cut_size': 100},\n",
       "  'morphologizer': {'factory': 'morphologizer',\n",
       "   'extend': True,\n",
       "   'model': {'@architectures': 'spacy.Tagger.v1',\n",
       "    'nO': None,\n",
       "    'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1',\n",
       "     'grad_factor': 1.0,\n",
       "     'pooling': {'@layers': 'reduce_mean.v1'},\n",
       "     'upstream': '*'}},\n",
       "   'overwrite': True,\n",
       "   'scorer': {'@scorers': 'spacy.morphologizer_scorer.v1'}},\n",
       "  'compound_splitter': {'factory': 'compound_splitter', 'split_mode': None},\n",
       "  'bunsetu_recognizer': {'factory': 'bunsetu_recognizer',\n",
       "   'remain_bunsetu_suffix': False},\n",
       "  'sentencizer': {'factory': 'sentencizer',\n",
       "   'overwrite': False,\n",
       "   'punct_chars': None,\n",
       "   'scorer': {'@scorers': 'spacy.senter_scorer.v1'}}},\n",
       " 'corpora': {'dev': {'@readers': 'spacy.Corpus.v1',\n",
       "   'path': '${paths.dev}',\n",
       "   'max_length': 0,\n",
       "   'gold_preproc': False,\n",
       "   'limit': 0,\n",
       "   'augmenter': None},\n",
       "  'train': {'@readers': 'spacy.Corpus.v1',\n",
       "   'path': '${paths.train}',\n",
       "   'max_length': 500,\n",
       "   'gold_preproc': False,\n",
       "   'limit': 0,\n",
       "   'augmenter': None}},\n",
       " 'training': {'accumulate_gradient': 3,\n",
       "  'dev_corpus': 'corpora.dev',\n",
       "  'train_corpus': 'corpora.train',\n",
       "  'seed': '${system.seed}',\n",
       "  'gpu_allocator': '${system.gpu_allocator}',\n",
       "  'dropout': 0.1,\n",
       "  'patience': 0,\n",
       "  'max_epochs': 0,\n",
       "  'max_steps': 50000,\n",
       "  'eval_frequency': 200,\n",
       "  'frozen_components': [],\n",
       "  'annotating_components': [],\n",
       "  'before_to_disk': None,\n",
       "  'batcher': {'@batchers': 'spacy.batch_by_padded.v1',\n",
       "   'discard_oversize': True,\n",
       "   'size': 2000,\n",
       "   'buffer': 256,\n",
       "   'get_length': None},\n",
       "  'logger': {'@loggers': 'spacy.ConsoleLogger.v1', 'progress_bar': False},\n",
       "  'optimizer': {'@optimizers': 'Adam.v1',\n",
       "   'beta1': 0.9,\n",
       "   'beta2': 0.999,\n",
       "   'L2_is_weight_decay': True,\n",
       "   'L2': 0.01,\n",
       "   'grad_clip': 1.0,\n",
       "   'use_averages': False,\n",
       "   'eps': 1e-08,\n",
       "   'learn_rate': {'@schedules': 'warmup_linear.v1',\n",
       "    'warmup_steps': 250,\n",
       "    'total_steps': 50000,\n",
       "    'initial_rate': 5e-05}},\n",
       "  'score_weights': {'dep_uas': 0.17,\n",
       "   'dep_las': 0.17,\n",
       "   'dep_las_per_type': None,\n",
       "   'sents_p': None,\n",
       "   'sents_r': None,\n",
       "   'sents_f': 0.07,\n",
       "   'ents_f': 0.17,\n",
       "   'ents_p': 0.0,\n",
       "   'ents_r': 0.0,\n",
       "   'ents_per_type': None,\n",
       "   'pos_acc': 0.1,\n",
       "   'morph_micro_f': 0.33,\n",
       "   'morph_per_feat': None,\n",
       "   'morph_acc': 0.0,\n",
       "   'tag_acc': 0.0}},\n",
       " 'pretraining': {},\n",
       " 'initialize': {'vectors': None,\n",
       "  'init_tok2vec': '${paths.init_tok2vec}',\n",
       "  'vocab_data': None,\n",
       "  'lookups': None,\n",
       "  'before_init': None,\n",
       "  'after_init': None,\n",
       "  'components': {},\n",
       "  'tokenizer': {}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sentencizer', <spacy.pipeline.sentencizer.Sentencizer object at 0x7f11e38a2080>)\n"
     ]
    }
   ],
   "source": [
    "for p in nlp.pipeline:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.ja.JapaneseTokenizer"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "…」を意味.....,,,,,,,. False\n",
      "PUNCT PUNCT\n",
      "する記号である。 True\n",
      "AUX PUNCT\n",
      "too much punct 23 10 0.43478260869565216\n",
      "アンパサンド（&amp;, ）は、並立助詞「…と…」を意味する記号である。 False\n",
      "AUX PUNCT\n",
      "too much punct 20 6 0.3\n",
      "ラテン語で「…と…」を表す接続詞 \"et\" の合字を起源とする。 False\n",
      "VERB PUNCT\n",
      "現代のフォントでも、Trebuchet MS など一部のフォントでは、\"et\" の合字であることが容易にわかる字形を使用している。 False\n",
      "AUX PUNCT\n",
      "語源. False\n",
      "NOUN PUNCT\n",
      "英語で教育を行う学校でアルファベットを復唱する場合、その文字自体が単語となる文字（\"A\", \"I\", かつては \" も）については、伝統的にラテン語の \"（それ自体）を用いて \"A per se A\" のように唱えられていた。 False\n",
      "AUX PUNCT\n",
      "また、アルファベットの最後に、27番目の文字のように \"&amp;\" を加えることも広く行われていた。\"& False\n",
      "SYM SYM\n",
      "too much punct 32 7 0.21875\n",
      "amp;\" はラテン語で \"et\" と読まれていたが、のちに英語で \"and\" と読まれるようになった。 False\n",
      "AUX PUNCT\n",
      "too much punct 32 8 0.25\n",
      "結果として、アルファベットの復唱の最後は \"X, Y, Z, \"and per se and\"\" という形になった。 False\n",
      "AUX PUNCT\n",
      "この最後のフレーズが繰り返されるうちに \"ampersand\" となまっていき、この言葉は1837年までには英語の一般的な語法となった。 False\n",
      "AUX PUNCT\n",
      "アンドレ＝マリ・アンペールがこの記号を自身の著作で使い、これが広く読まれたため、この記号が \"Ampère's and\" と呼ばれるようになったという誤った語源俗説がある。 False\n",
      "VERB PUNCT\n",
      "歴史. False\n",
      "NOUN PUNCT\n",
      "アンパサンドの起源は1世紀の古ローマ筆記体にまでさかのぼることができる。 True\n",
      "VERB PUNCT\n",
      "古ローマ筆記体では、E と T はしばしば合字として繋げて書かれていた（左図「アンパサンドの変遷」の字形1）。 False\n",
      "PUNCT PUNCT\n",
      "それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。 True\n",
      "AUX PUNCT\n",
      "字形2と3は4世紀中頃における et の合字の例である。 False\n",
      "AUX PUNCT\n",
      "その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れていった。 True\n",
      "AUX PUNCT\n",
      "しかし、et の合字は使われ続け、次第に元の文字がわかりにくい字形に変化していった（字形4から6）。 False\n",
      "PUNCT PUNCT\n",
      "現代のイタリック体のアンパサンドは、ルネサンス期に発展した筆記体での et の合字にさかのぼる。 False\n",
      "VERB PUNCT\n",
      "1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアンパサンドの両方を多用するようになった。 True\n",
      "AUX PUNCT\n",
      "アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語でアンパサンドが使用されるようになった。 True\n",
      "AUX PUNCT\n",
      "アンパサンドはしばしばラテンアルファベットの最後の文字とされることがあった。 True\n",
      "AUX PUNCT\n",
      "たとえば1011年のの文字表がその例である。 True\n",
      "AUX PUNCT\n",
      "同様に、\"&amp;\" は英語アルファベットの27番目の文字とされ、アメリカ合衆国やその他の地域でも、子供達はアンパサンドはアルファベットの最後の文字だと教えられていた。 False\n",
      "AUX PUNCT\n",
      "1863年の M. False\n",
      "NOUN PUNCT\n",
      "B. False\n",
      "NOUN PUNCT\n",
      "Moore の著書 \"The Dixie Primer, for the Little Folks\" にその一例を見ることができる。 False\n",
      "VERB PUNCT\n",
      "ジョージ・エリオットは、1859年に発表した小説「」の中で、Jacob Storey に次のセリフを語らせている。\" False\n",
      "PUNCT SYM\n",
      "He thought it [Z] had only been put to finish off th' alphabet like; though ampusand would ha' done as well, for what he could see.\" False\n",
      "PUNCT SYM\n",
      "よく知られた童謡の は \"X, Y, Z, and ampersand, All wished for a piece in hand\" という歌詞で締めくくられる。 False\n",
      "AUX PUNCT\n",
      "アンパサンドは、ティロ式記号の et (\"⁊\", Unicode U+204A) とは別のものである。 False\n",
      "AUX PUNCT\n",
      "ティロ式記号の et は、アンパサンドと意味は同じだが数字の「7」に似た形の記号である。 False\n",
      "AUX PUNCT\n",
      "両者はともに古代から使用され、中世を通してラテン語の \"et\" を表すために使用された。 False\n",
      "AUX PUNCT\n",
      "しかし、アンパサンドとティロ式記号の et はそれぞれ独立に発明されたものである。 False\n",
      "AUX PUNCT\n",
      "too much punct 43 9 0.20930232558139536\n",
      "ラテン文字から発展した古アイルランド語の文字では、アイルランド語の \"agus\"（「…と…」）を表すためにティロ式記号の et が使用されていた。 False\n",
      "AUX PUNCT\n",
      "今日はゲール文字の一部として主に装飾的な目的で使用されている。 True\n",
      "AUX PUNCT\n",
      "この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。 True\n",
      "VERB PUNCT\n",
      "手書き. False\n",
      "NOUN PUNCT\n",
      "日常的な手書きの場合、欧米では小文字の （エプシロン）を大きくしたもの（あるいは数字の \"3\" の鏡文字）に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。 True\n",
      "AUX PUNCT\n",
      "また、エプシロンの上下に縦線または点を付けたものもしばしば使われる。 True\n",
      "AUX PUNCT\n",
      "くだけた用法として、プラス記号（\"+\", この記号もまた et の合字である）がアンパサンドの代わりに使われることがある。 False\n",
      "VERB PUNCT\n",
      "また、プラス記号に輪を重ねたような、無声歯茎側面摩擦音を示す発音記号「」のようなものが使われることもある。 True\n",
      "VERB PUNCT\n",
      "同様の記号. False\n",
      "NOUN PUNCT\n",
      "too much punct 26 6 0.23076923076923078\n",
      "ティロの速記には「et」を表すための「」(U+204A Tironian sign et)がある。 False\n",
      "VERB PUNCT\n",
      "この文字はドイツのフラクトゥールで使われたほか、ゲール文字でも使用される。 True\n",
      "AUX PUNCT\n",
      "too much punct 39 8 0.20512820512820512\n",
      "ギリシア文字では「……と」を意味するを表すための合字として「」(U+03D7 Greek kai symbol)が使われることがある。 False\n",
      "VERB PUNCT\n",
      "プログラミング言語. False\n",
      "NOUN PUNCT\n",
      "プログラミング言語では、C など多数の言語で AND 演算子として用いられる。 False\n",
      "AUX PUNCT\n",
      "以下は C の例。 False\n",
      "NOUN PUNCT\n",
      "PHPでは、変数宣言記号（$）の直前に記述することで、参照渡しを行うことができる。 False\n",
      "VERB PUNCT\n",
      "BASIC 系列の言語では文字列の連結演算子として使用される。 False\n",
      "AUX PUNCT\n",
      "codice_4 は codice_5 を返す。 False\n",
      "VERB PUNCT\n",
      "また、主にマイクロソフト系では整数の十六進表記に codice_6 を用い、codice_7 （十進で15）のように表現する。 False\n",
      "AUX PUNCT\n",
      "SGML、XML、HTMLでは、アンパサンドを使ってSGML実体を参照する。 False\n",
      "AUX PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(sent, is_good(sent))\n",
    "    print(sent[-2].pos_, sent[-1].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11 6\n",
      "AUX\n",
      "AUX\n",
      "AUX\n",
      "SYM\n",
      "NUM\n",
      "PUNCT\n",
      "False\n",
      "[(False, 'する'), (False, 'する'), (False, 'する'), (True, '&'), (False, '4'), (True, '.')]\n",
      "[(True, 'する'), (True, 'する'), (True, 'する'), (False, '&'), (False, '4'), (False, '.')]\n"
     ]
    }
   ],
   "source": [
    "ex = 'する する する&4.'\n",
    "\n",
    "doc = nlp.tokenizer(ex)\n",
    "tok_ez = list(doc)\n",
    "print(len(doc), len(doc.text), len(list(doc)))\n",
    "[print(t.pos_) for t in doc]\n",
    "print(is_good(ex, tokenizer=nlp.tokenizer))\n",
    "punct_count = sum([token.is_punct for token in doc])\n",
    "print([(token.is_punct, token.text) for token in doc])\n",
    "print([(token.is_alpha, token.text) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = doc[0]\n",
    "token.is_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12285\n",
      "1058\n",
      "1038\n",
      "1\n",
      "new chunk\n",
      "True 17\n",
      "True 29\n",
      "True 30\n",
      "True 34\n",
      "True 29\n",
      "True 17\n",
      "True 13\n",
      "True 21\n",
      "False 27\n",
      "この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。\"\n",
      "False 49\n",
      "日常的な手書きの場合、欧米では小文字の（エプシロン）を大きくしたもの（あるいは数字の\"\"3\"\"の鏡文字）に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。\"\n",
      "True 19\n",
      "True 33\n",
      "True 20\n",
      "True 17\n",
      "False 54\n",
      "言語は、人間が用いる意志伝達手段であり、社会集団内で形成習得され、意志を相互に伝達することや、抽象的な思考を可能にし、結果として人間の社会的活動や文化的活動を支えている。\n",
      "True 48\n",
      "too much punct 41 10 0.24390243902439024\n",
      "False 41\n",
      "too much punct 41 10 0.24390243902439024\n",
      "音韻》と《意味》の間の結び付け方、また、《文字》と音韻・形態素・単語との間の結び付け方は、社会的に作られている習慣である。\n",
      "True 41\n",
      "True 34\n",
      "True 24\n",
      "True 9\n"
     ]
    }
   ],
   "source": [
    "## wiki debug long text\n",
    "max_chunk_size = int(49140 / 4)\n",
    "#max_chunk_size = int(10e7)\n",
    "\n",
    "print(max_chunk_size)\n",
    "bug = \"\"\"アンパサンドの起源は1世紀の古ローマ筆記体にまでさかのぼることができる。\n",
    "それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。\n",
    "その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れていった。\n",
    "1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアンパサンドの両方を多用するようになった。\n",
    "アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語でアンパサンドが使用されるようになった。\n",
    "アンパサンドはしばしばラテンアルファベットの最後の文字とされることがあった。\n",
    "たとえば1011年のの文字表がその例である。\n",
    "今日はゲール文字の一部として主に装飾的な目的で使用されている。\n",
    "この文字はアイルランドにおけるキリスト教時代初期に修道院の影響によって書き文字に加わった可能性がある。\n",
    "\"日常的な手書きの場合、欧米では小文字の（エプシロン）を大きくしたもの（あるいは数字の\"\"3\"\"の鏡文字）に縦線を加えた形の単純化されたアンパサンドがしばしば使われる。\"\n",
    "また、エプシロンの上下に縦線または点を付けたものもしばしば使われる。\n",
    "また、プラス記号に輪を重ねたような、無声歯茎側面摩擦音を示す発音記号「」のようなものが使われることもある。\n",
    "この文字はドイツのフラクトゥールで使われたほか、ゲール文字でも使用される。\n",
    "言語（げんご）は、狭義には「声による記号の体系」をいう。\n",
    "言語は、人間が用いる意志伝達手段であり、社会集団内で形成習得され、意志を相互に伝達することや、抽象的な思考を可能にし、結果として人間の社会的活動や文化的活動を支えている。\n",
    "言語には、文化の特徴が織り込まれており、共同体で用いられている言語の習得をすることによって、その共同体での社会的学習、および人格の形成をしていくことになる。\n",
    "音韻》と《意味》の間の結び付け方、また、《文字》と音韻・形態素・単語との間の結び付け方は、社会的に作られている習慣である。\n",
    "言語と非言語の境界が問題になるが、文字を使う方法と文字を用いない方法の区別のみで、言語表現を非言語表現から区別することはできない。\n",
    "抽象記号には文字表現と非文字表現（積分記号やト音記号など）があり、文字表現は言語表現と文字記号に分けられる。\n",
    "化学式は自然言語の文法が作用しておらず、化学式独特の文法で構成されている。\n",
    "言語にはさまざまな分類がある。\"\"\"\n",
    "print(len(bug))\n",
    "bug = re.sub(r'[\\n\\t]', '', bug)\n",
    "print(len(bug))\n",
    "\n",
    "\n",
    "chunks = [bug[i:i+max_chunk_size] for i in range(0, len(bug), max_chunk_size)]\n",
    "print(len(chunks))\n",
    "docs = nlp.pipe(chunks)\n",
    "for doc in docs:\n",
    "    print('new chunk')\n",
    "    for sent in doc.sents:\n",
    "        print(is_good(sent), len(sent))\n",
    "        #print(sent)\n",
    "        if not is_good(sent):\n",
    "            print(repr(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
