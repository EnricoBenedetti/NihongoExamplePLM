{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in general we need to keep track of where the token of the word is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/enrico_benedetti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from helper import *\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional.pairwise import pairwise_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(query, sentence, tokenizer, verbose=False):\n",
    "    \"\"\"input:\n",
    "    query: the target word to find the span for. (if already a doc it should be faster)\n",
    "    sentence: the sentence. (can be a doc - it will be faster)\n",
    "    tokenizer: the tokenizer. assumed a direct __call__ method (e.g. from spacy tokenizers)\n",
    "\n",
    "    output: \n",
    "    spans_ids_char, spans_ids_spacy: two lists of lists of tuples\n",
    "    each list of tuples [(s, e)_i]: list of start and end idx of matches. one can take only the first one if needed.\n",
    "    if no match is found, a tuple of empty lists is returned.\"\"\"\n",
    "\n",
    "    matcher = spacy.matcher.Matcher(tokenizer.vocab)\n",
    "    # tokenize \n",
    "    if isinstance(sentence, spacy.tokens.doc.Doc):\n",
    "        sentence_tokens = sentence\n",
    "    else:\n",
    "        sentence_tokens = tokenizer(sentence) # this is prob the heavy one\n",
    "\n",
    "    if isinstance(query, spacy.tokens.doc.Doc):\n",
    "        query_tokens = query\n",
    "    else:\n",
    "       query_tokens = tokenizer(query) # this is prob the heavy one - shorter tho\n",
    "    \n",
    "    pattern = [ {\"LEMMA\": query_token.lemma_} for query_token in query_tokens]\n",
    "    matcher.add(\"query_match\", [pattern])\n",
    "\n",
    "    # get matches as id, start, end\n",
    "    matches = matcher(sentence_tokens)\n",
    "    # delete this particular one to avoid matching later\n",
    "    matcher.remove(\"query_match\")\n",
    "\n",
    "    results_char = []\n",
    "    results_spacy = []\n",
    "    for match_id, start, end in matches:\n",
    "        span_doc = sentence_tokens[start:end]\n",
    "        #span_str = sentence_tokens.text[span_doc.start_char:span_doc.end_char]\n",
    "        # if verbose:\n",
    "        #     print(f'sentence: {sentence}')\n",
    "        #     print(f'Span(token): {sentence_tokens[start:end]} , Span(str): {span_str}')\n",
    "        #     print(f'str: {span_doc.start_char,span_doc.end_char} , indeces: {start, end}')\n",
    "        results_char.append((span_doc.start_char, span_doc.end_char))\n",
    "        results_spacy.append((start, end))\n",
    "\n",
    "    return results_char, results_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico_benedetti/anaconda3/envs/nlp_env/lib/python3.8/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'ja_ginza' (5.1.3) was trained with spaCy v3.2.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('ja_ginza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the mirorwic model\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load the BERT Large model\n",
    "model_name = \"bennexx/mirrorwic-cl-tohoku-bert-base-japanese-v3\"\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input text\n",
    "text = \"Hugging Face is creating wonderful NLP models!\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(text, add_special_tokens=True, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1461153ea969434399a01176899848c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"bennexx/jp_sentences\")\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>それに伴い、各種問い合わせを受付開始いたします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>英語とか韓国語、中国語での出版も希望しています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704955</th>\n",
       "      <td>1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704956</th>\n",
       "      <td>1901年8月17日、高等工業学校が追加された。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704957</th>\n",
       "      <td>1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704958</th>\n",
       "      <td>1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704959</th>\n",
       "      <td>カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704960 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "0            藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。\n",
       "1                    朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。\n",
       "2                特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。\n",
       "3                             それに伴い、各種問い合わせを受付開始いたします。\n",
       "4                             英語とか韓国語、中国語での出版も希望しています。\n",
       "...                                                ...\n",
       "12704955          1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。\n",
       "12704956                      1901年8月17日、高等工業学校が追加された。\n",
       "12704957            1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。\n",
       "12704958  1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。\n",
       "12704959              カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。\n",
       "\n",
       "[12704960 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['明日', '、', '彼', 'は', '休暇', 'を', '取り', 'ます', '。'], ['彼', 'は', '本', 'を', '取っ', 'て', '読ん', 'で', 'い', 'ます', '。'], ['彼', 'は', '賞', 'を', '取る', 'こと', 'が', 'でき', 'まし', 'た', '。'], ['彼女', 'は', '試験', 'で', '高得点', 'を', '取り', 'まし', 'た', '。']]\n"
     ]
    }
   ],
   "source": [
    "#sentences = [\"日本語能力試験は簡単です。\", \"私は、日本語能力試験したことがなかった。\"]\n",
    "sentences = ['明日、彼は休暇を取ります。', '彼は本を取って読んでいます。', '彼は賞を取ることができました。', '彼女は試験で高得点を取りました。']\n",
    "#target_word = '日本語能力試験' \n",
    "target_word = '取る'\n",
    "\n",
    "pretoken_sentences = list(nlp.pipe(sentences))\n",
    "pretoken_sentences = [[t.orth_ for t in doc ]for doc in pretoken_sentences]\n",
    "print(pretoken_sentences)\n",
    "#tokenized_text = tokenizer.batch_encode_plus(pretoken_sentences, is_split_into_words=True, truncation = True, padding=\"max_length\", max_length=50)\n",
    "#print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spans_ids_char, spans_ids_spacy = get_spans(query=target_word, sentence=sentences[0], tokenizer=nlp.tokenizer)\n",
    "# # span_char = spans_ids_char[0]\n",
    "# # span_spacy = spans_ids_spacy[0]\n",
    "# target_word_start, target_word_end = spans_ids_char[0] # take first one\n",
    "# sentences[0][target_word_start:target_word_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtoken_start, subtoken_end = sum(subtokens_per_token[:target_word_start]), sum(subtokens_per_token[:target_word_end])\n",
    "# subtoken_start, subtoken_end = get_subtoken_span(subtokens_per_token, span_spacy)\n",
    "# print(subtoken_start, subtoken_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(flattened_inputs.cuda(), output_hidden_states=True)\n",
    "# layer_start = 9\n",
    "# layer_end = 13\n",
    "# hidden_states = output.hidden_states # the first number is the layer, second is the token number, last is the vector\n",
    "# average_layer_batch = sum(hidden_states[layer_start:layer_end]) / (layer_end-layer_start) # we get the token mean across the last layers\n",
    "# sentence_num_in_batch = average_layer_batch.size()[0]\n",
    "# for num in range(sentence_num_in_batch): # for all sentences passed\n",
    "#     # here we need the start/end on subtokens\n",
    "#     ###\n",
    "\n",
    "#     print(average_layer_batch[num].size()) \n",
    "#     sentence_embeddings = average_layer_batch[num] # get a tensor num_tokens(hf) x 768 vector values\n",
    "#     print(sentence_embeddings[0].shape) # sentence_embeddings[i] is the embedding of subtoken i. to get the ones for the original words we need to...\n",
    "#     sentence_embeddings_no_st = sentence_embeddings[1:-1]# remove first and last (they are the cls and sep ones)\n",
    "#     print(sentence_embeddings_no_st.shape) # find the embeddings of interest (the one for a certain target word) and sum? also between them / or take the first one?\n",
    "    \n",
    "#     target_word_embeddings = sentence_embeddings_no_st[subtoken_start:subtoken_end] # those are the corresponding embeddings\n",
    "#     target_word_emb_final = target_word_embeddings.detach().cpu().numpy().mean(0) # take the mean\n",
    "#     print(\"mean\", target_word_emb_final.shape)\n",
    "#     target_word_emb_final = target_word_embeddings[0].detach().cpu().numpy() # take the first token only\n",
    "#     print(\"first\", target_word_emb_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_spans = []\n",
    "# subtoken_spans = []\n",
    "# batch_flattened_inputs = []\n",
    "# for sentence, pretoken_sentence in zip(sentences, pretoken_sentences):\n",
    "#     # process tokens in the batch\n",
    "#     # these 2 for every sentence in the batch?\n",
    "#     flattened_inputs, grouped_inputs, subtokens_per_token = tokenize_for_sense_embeddings(pretokenized_sentence=pretoken_sentence, tokenizer=tokenizer)\n",
    "#     batch_flattened_inputs.append(flattened_inputs.tolist()[0]) # depack the batch\n",
    "\n",
    "#     spans_ids_char, spans_ids_spacy = get_spans(query=target_word, sentence=sentence, tokenizer=nlp.tokenizer)\n",
    "#     spans_ids_char = spans_ids_char[0] # take first occurrence\n",
    "#     spans_ids_spacy = spans_ids_spacy[0] # take first occurrence\n",
    "#     sentence_spans.append(spans_ids_spacy)  \n",
    "#     #print(sentence_spans)\n",
    "#     #print(subtokens_per_token)\n",
    "#     subtoken_span = get_subtoken_span(subtokens_per_token, spans_ids_spacy)\n",
    "#     subtoken_spans.append(subtoken_span)\n",
    "\n",
    "# # need to pad and stuff...\n",
    "# #print(batch_flattened_inputs)\n",
    "# batch_flattened_inputs = tokenizer.batch_encode_plus(batch_flattened_inputs, is_split_into_words=True, add_special_tokens=False, padding=True, truncation=True, return_tensors='pt')\n",
    "# #batch_flattened_inputs = torch.stack(batch_flattened_inputs, dim=0)\n",
    "\n",
    "# print(subtoken_spans)\n",
    "# print(batch_flattened_inputs)\n",
    "\n",
    "\n",
    "# embeddings = get_embeddings(flattened_inputs=batch_flattened_inputs, subtoken_spans=subtoken_spans, model=model)\n",
    "\n",
    "# pairwise_cosine_similarity(torch.Tensor(embeddings), zero_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mrklie.com/post/2020-09-26-pretokenized-bert/\n",
    "def tokenize_for_sense_embeddings(pretokenized_sentence, tokenizer):\n",
    "    \"\"\"Processes a pretokenized sentence\n",
    "    Input:\n",
    "    tokenizer: the hf tokenizer\"\"\"\n",
    "    grouped_inputs = [torch.LongTensor([tokenizer.cls_token_id])]\n",
    "    subtokens_per_token = []\n",
    "\n",
    "    for token in pretokenized_sentence:\n",
    "        tokens = tokenizer.encode(\n",
    "            token,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=False,\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        ).squeeze(axis=0)\n",
    "        grouped_inputs.append(tokens)\n",
    "        subtokens_per_token.append(len(tokens))\n",
    "\n",
    "    grouped_inputs.append(torch.LongTensor([tokenizer.sep_token_id]))\n",
    "\n",
    "    flattened_inputs = torch.cat(grouped_inputs)\n",
    "    flattened_inputs = torch.unsqueeze(flattened_inputs, 0)\n",
    "    return flattened_inputs, grouped_inputs, subtokens_per_token\n",
    "\n",
    "def get_subtoken_span(subtokens_per_token, span_spacy):\n",
    "    \"\"\"Gets the start and end of subtokens from the spacy span.\"\"\"\n",
    "    target_word_start, target_word_end = span_spacy\n",
    "    return sum(subtokens_per_token[:target_word_start]), sum(subtokens_per_token[:target_word_end])\n",
    "\n",
    "def get_embeddings(flattened_inputs, subtoken_spans, model, layer_start = 9, layer_end = 13, method='mean'):\n",
    "    \"\"\"Gets the embeddings from the model on the average of layers. \n",
    "\n",
    "    Input: \n",
    "    flattened_inputs: the tokenized (hf) ids, expects a batch.\n",
    "    subtoken_span: the corresponding subtoken spans to extract. also a batch.\n",
    "    layer_start, layer_end: which layers to average embeddings.\n",
    "    method: first, mean, sum. does not change much\n",
    "    \n",
    "    output:\n",
    "    a batch of final embeddings for the subtoken_spans which correspond to the target word.\"\"\"\n",
    "\n",
    "    output = model(input_ids=flattened_inputs['input_ids'].cuda(),attention_mask=flattened_inputs['attention_mask'].cuda(), output_hidden_states=True)\n",
    "    hidden_states = output.hidden_states # the first number is the layer, second is the token number, last is the vector\n",
    "    average_layer_batch = sum(hidden_states[layer_start:layer_end]) / (layer_end-layer_start) # we get the token mean across the last layers\n",
    "    sentence_num_in_batch = average_layer_batch.size()[0]\n",
    "    \n",
    "    out_tensors = []\n",
    "\n",
    "    for num in range(sentence_num_in_batch): # for all sentences passed\n",
    "    # here we need the start/end on subtokens\n",
    "    ###\n",
    "        #print(average_layer_batch[num].size()) \n",
    "        sentence_embeddings = average_layer_batch[num] # get a tensor num_tokens(hf) x 768 vector values\n",
    "        #print(sentence_embeddings[0].shape) # sentence_embeddings[i] is the embedding of subtoken i. to get the ones for the original words we need to...\n",
    "        sentence_embeddings_no_st = sentence_embeddings[1:-1]# remove first and last (they are the cls and sep ones) - ok theres also the pad but they are right-side\n",
    "        #print(sentence_embeddings_no_st.shape) # find the embeddings of interest (the one for a certain target word) and sum? also between them / or take the first one?\n",
    "        \n",
    "        subtoken_start, subtoken_end =  subtoken_spans[num] # get the current spans / the one of the batch\n",
    "        target_word_embeddings = sentence_embeddings_no_st[subtoken_start:subtoken_end] # those are the corresponding embeddings\n",
    "        if method=='sum':\n",
    "            target_word_emb_final = target_word_embeddings.sum(0)\n",
    "        elif method=='mean':\n",
    "            target_word_emb_final = target_word_embeddings.mean(0)#.detach().cpu().numpy().mean(0) # take the mean\n",
    "        elif method=='first':\n",
    "            target_word_emb_final = target_word_embeddings[0]#.detach().cpu().numpy() # take the first token only\n",
    "        # checking\n",
    "        #print(target_word_emb_final)\n",
    "        detokenized = tokenizer.batch_decode(flattened_inputs['input_ids'][num])[1:-1] # yes\n",
    "        corresponding_tokens = detokenized[subtoken_start: subtoken_end]\n",
    "        print(corresponding_tokens)\n",
    "\n",
    "        #print(\"mean\", target_word_emb_final.shape)\n",
    "        \n",
    "        #print(\"first\", target_word_emb_final.shape)\n",
    "        out_tensors.append(target_word_emb_final)\n",
    "\n",
    "    out_tensor = torch.stack(out_tensors, dim=0)\n",
    "    return out_tensor.detach().cpu().numpy()\n",
    "\n",
    "def get_sense_similarity(sentences: list, target_word, nlp, model, tokenizer, method='mean'):\n",
    "    \"\"\"Returns the similarity matrix and the embeddings.\"\"\"\n",
    "    pretoken_sentences = list(nlp.pipe(sentences))\n",
    "    pretoken_sentences = [[t.orth_ for t in doc ]for doc in pretoken_sentences]\n",
    "    sentence_spans = []\n",
    "    subtoken_spans = []\n",
    "    batch_flattened_inputs = []\n",
    "    # list of indeces to zero the distances for in the matrix\n",
    "    i_zero_list = []\n",
    "    for i, (sentence, pretoken_sentence) in enumerate(zip(sentences, pretoken_sentences)):\n",
    "        # process tokens in the batch\n",
    "        # these 2 for every sentence in the batch?\n",
    "        flattened_inputs, grouped_inputs, subtokens_per_token = tokenize_for_sense_embeddings(pretokenized_sentence=pretoken_sentence, tokenizer=tokenizer)\n",
    "        batch_flattened_inputs.append(flattened_inputs.tolist()[0]) # depack the batch\n",
    "\n",
    "        spans_ids_char, spans_ids_spacy = get_spans(query=target_word, sentence=sentence, tokenizer=nlp.tokenizer)\n",
    "        # if empty, remember the sentence and set the distance to 0 later. give a 0,0 subtoken span\n",
    "        if len(spans_ids_char) == 0:\n",
    "            subtoken_span = (0,0)\n",
    "            i_zero_list.append(i)\n",
    "        else:\n",
    "            # do it normally\n",
    "            spans_ids_char = spans_ids_char[0] # take first occurrence\n",
    "            spans_ids_spacy = spans_ids_spacy[0] # take first occurrence\n",
    "            sentence_spans.append(spans_ids_spacy)  \n",
    "            #print(sentence_spans)\n",
    "            #print(subtokens_per_token)\n",
    "            subtoken_span = get_subtoken_span(subtokens_per_token, spans_ids_spacy)\n",
    "        subtoken_spans.append(subtoken_span)\n",
    "\n",
    "    # need to pad and stuff...\n",
    "    #print(batch_flattened_inputs)\n",
    "    batch_flattened_inputs = tokenizer.batch_encode_plus(batch_flattened_inputs, is_split_into_words=True, add_special_tokens=False, padding=True, truncation=True, return_tensors='pt')\n",
    "    #batch_flattened_inputs = torch.stack(batch_flattened_inputs, dim=0)\n",
    "\n",
    "    #print(subtoken_spans)\n",
    "    #print(batch_flattened_inputs)\n",
    "\n",
    "\n",
    "    embeddings = get_embeddings(flattened_inputs=batch_flattened_inputs, subtoken_spans=subtoken_spans, model=model, method=method)\n",
    "    similarity_matrix = pairwise_cosine_similarity(torch.Tensor(embeddings), zero_diagonal=True)\n",
    "\n",
    "    # for the parts where there are no target words, fill with -1s\n",
    "    similarity_matrix[:, i_zero_list] = -1\n",
    "    similarity_matrix[i_zero_list, :] = -1\n",
    "    # re_zero diagonal\n",
    "    similarity_matrix.fill_diagonal_(0)\n",
    "    #print(i_zero_list)\n",
    "\n",
    "    return similarity_matrix, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['取 り']\n",
      "['取 っ']\n",
      "['取 る']\n",
      "['取 り']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.08049724,  0.00812712, -0.22313227, ..., -0.19238411,\n",
       "          0.07798383, -0.4647833 ],\n",
       "        [-0.3224555 , -0.45918953, -0.52518886, ...,  0.4306293 ,\n",
       "          0.18063447,  0.6098743 ],\n",
       "        [-0.02311909,  0.8989869 , -0.79339576, ..., -0.91200066,\n",
       "          0.5188445 , -0.08833297],\n",
       "        [-0.2956479 ,  0.40284643, -0.17048827, ..., -0.13746454,\n",
       "          1.1316245 , -0.4609816 ]], dtype=float32),\n",
       " tensor([[0.0000, 0.4925, 0.4664, 0.5221],\n",
       "         [0.4925, 0.0000, 0.4587, 0.4700],\n",
       "         [0.4664, 0.4587, 0.0000, 0.7712],\n",
       "         [0.5221, 0.4700, 0.7712, 0.0000]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on 100 sentences\n",
    "# what to do if not found... probably give zero and skip - or consider that they will be there for sure\n",
    "#get_sense_similarity(df['sentence'][:100], target_word='target_word', nlp=nlp, model=model, tokenizer=tokenizer)\n",
    "get_sense_similarity(sentences, target_word=target_word, nlp=nlp, model=model, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
