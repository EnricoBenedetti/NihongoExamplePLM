{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import utils\n",
    "import pandas as pd\n",
    "import spacy\n",
    "#from utils import *\n",
    "import time\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          彼は仕事で成功していないので、彼女から相手にされていない。\n",
       "2        東と西が互いに相手を非難するプロパガンダ放送を流し合っていた。\n",
       "3                 日本では、「相手」という言葉はよく使われる。\n",
       "4                  あなたには何でも相談できる相手がいますね。\n",
       "5    東と西はそれぞれ互いに相手を非難するプロパガンダ放送を流し合っていた。\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of what we want to write\n",
    "#df_targets = pd.read_csv(\"/data/enrico_benedetti/nihongoexample/data/targets/target_words.csv\")\n",
    "df_targets = pd.read_csv(\"../../data/targets/target_words.csv\")\n",
    "row = df_targets.loc[0]\n",
    "target_word = row['target_word']\n",
    "context_sentence = row['context_sentence']\n",
    "k=5\n",
    "target_level = \"N5\"\n",
    "sys_out_filename = f\"../../evaluation/outputs/generation/llm_jp/{target_word}_{target_level}_.csv\"\n",
    "df = pd.read_csv(sys_out_filename)\n",
    "df\n",
    "\n",
    "sys_sentences = df['sentence'][1:k+1]\n",
    "sys_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.gspread.org/en/latest/oauth2.html#for-bots-using-service-account\n",
    "gc = gspread.service_account()\n",
    "#gc = gspread.service_account(filename='../../service_account_secret.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.open(\"Evaluation-sheet-jp-v3.0_gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows[13] # i have to cycle here and reconstruct the things. \n",
    "\n",
    "# maybe a function that processes one block is good:\n",
    "\n",
    "def get_block_info(block_list: list):\n",
    "    \"\"\"Parses block read from google sheets\"\"\"\n",
    "    target_levels = ['N1', 'N2', 'N3', 'N4', 'N5']\n",
    "    k = 5\n",
    "    block = block_list\n",
    "    result = {}\n",
    "    first_line = block[0]\n",
    "    \n",
    "    assert(first_line[0:4] == [' Context sentence','Target level','Target word','Block ID'])\n",
    "    second_line = block[1]\n",
    "    result['context_sentence'] = second_line[0]\n",
    "    result['target_level'] = second_line[1]\n",
    "\n",
    "    assert(result['target_level'] in target_levels)\n",
    "    result['target_word'] = second_line[2]\n",
    "    result['block_id'] = second_line[3]\n",
    "\n",
    "    third_line = block[2]\n",
    "    assert(len(third_line) >= 9)\n",
    "\n",
    "    lists = block[4:4+k]\n",
    "    sys_sentences = pd.DataFrame(lists, columns=['sentence','level_human','sense_human', 'reject_human']*3)\n",
    "\n",
    "    sys_sentences = sys_sentences.rename(columns={0: 'sentence', 1: 'level_human', 2: 'sense_human', 3: 'reject_human'})\n",
    "    # display(sys_sentences)\n",
    "    result['sys_1'] = {}\n",
    "    result['sys_2'] = {}\n",
    "    result['sys_3'] = {}\n",
    "\n",
    "    result['sys_1']['sentences'] = sys_sentences.iloc[:,0:3]\n",
    "    result['sys_2']['sentences'] = sys_sentences.iloc[:,3:6]\n",
    "    result['sys_3']['sentences'] = sys_sentences.iloc[:,6:9]\n",
    "    \n",
    "    diversity_line = [item for item in block[10] if item != '']\n",
    "    result['sys_1']['diversity_human'] = diversity_line[0]\n",
    "    result['sys_2']['diversity_human'] = diversity_line[1]\n",
    "    result['sys_3']['diversity_human'] = diversity_line[2]\n",
    "\n",
    "    rank_line = [item for item in block[12] if item != '']\n",
    "    result['sys_1']['rank_human'] = rank_line[0]\n",
    "    result['sys_2']['rank_human'] = rank_line[1]\n",
    "    result['sys_3']['rank_human'] = rank_line[2]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how to analyze stuff... with this structure\n",
    "# we should linearize it also\n",
    "def get_block_info_flat(block_list: list):\n",
    "    \"\"\"Parses block read from google sheets into a one sentence per line dataframe.\"\"\"\n",
    "    target_levels = ['N1', 'N2', 'N3', 'N4', 'N5']\n",
    "    k = 5\n",
    "    block = block_list\n",
    "    result = []\n",
    "    first_line = block[0]\n",
    "    second_line = block[1]\n",
    "    assert(first_line[0:4] == [' Context sentence','Target level','Target word','Block ID']) # careful with space\n",
    "    # need to build dataframe rows as 'target word / ctx / level / blockid / sys id / sentence / diff human /\n",
    "    # sense human / reject / syn diversity (repeated) / ranking (repeated)' then we can group and count easily\n",
    "    # later we need to add the annotator and other info\n",
    "\n",
    "    for sys_id in [1,2,3]:\n",
    "        for i in range(k):\n",
    "            df_element = {}\n",
    "            \n",
    "            # this part is common to all\n",
    "            df_element['target_word'] = second_line[2]\n",
    "            df_element['context_sentence'] = second_line[0]\n",
    "            df_element['target_level'] = second_line[1]\n",
    "            df_element['block_id'] = second_line[3]\n",
    "            df_element['sys_id'] = sys_id\n",
    "\n",
    "            assert(df_element['target_level'] in target_levels)\n",
    "\n",
    "            third_line = block[2]\n",
    "            assert(len(third_line) >= 9)\n",
    "\n",
    "\n",
    "            # this part is common to system but we replicate\n",
    "            # reading normally fails when there is no annotation (last blank line does not get downloaded)\n",
    "            # so we fill it automatically with blank\n",
    "            df_element['diversity_human'] = block[10][0+sys_id-1+3*(sys_id-1)]\n",
    "            try:\n",
    "                df_element['rank_human'] = block[12][0+sys_id-1+3*(sys_id-1)]\n",
    "            except IndexError:\n",
    "                df_element['rank_human'] = ''\n",
    "\n",
    "            # this part is unique - 5 should stay because everything is at the same height\n",
    "            df_element['sentence'] = block[4+i][0+sys_id-1 + 3*(sys_id-1)]\n",
    "            df_element['level_human'] = block[4+i][1+sys_id-1 + 3*(sys_id-1)]\n",
    "            df_element['sense_human'] = block[4+i][2+sys_id-1 + 3*(sys_id-1)]\n",
    "            df_element['reject'] = block[4+i][3+sys_id-1 + 3*(sys_id-1)]\n",
    "            # fix cases where reject is blank -> transform into 'FALSE'\n",
    "            if df_element['reject'] != 'TRUE' and df_element['rank_human'] != '':\n",
    "                df_element['reject'] = 'FALSE'\n",
    "            #otherwise it stays '' therefore nan later\n",
    "            elif df_element['reject'] != 'TRUE': df_element['reject'] = ''\n",
    "\n",
    "            if df_element['reject'] == 'TRUE':\n",
    "                df_element['sense_human'] = 'rejected'\n",
    "                df_element['level_human'] = 'rejected'\n",
    "                \n",
    "            result.append(df_element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets all results from a file (and therefore all sheets)\n",
    "# Rembemer to share with : human-eval@nii-thesis.iam.gserviceaccount.com\n",
    "#sheet_name = 'Evaluation-sheet-jp-v3.0_gpt4' # it is gpt_4\n",
    "#annotator_id = 'gpt4'\n",
    "#sheet_name = 'Henri_Enrico_Evaluation-sheet-jp-v3.0' #  is human_learner_1\n",
    "#annotator_id = 'human_learner_1'\n",
    "#sheet_name = 'Willy_Enrico_Evaluation-sheet-jp-v3.0' #  is human_learner_2\n",
    "#annotator_id = 'human_learner_2'\n",
    "#sheet_name = 'Aizawa_Enrico_Evaluation-sheet-jp-v3.0' #  is human_native_1\n",
    "#annotator_id = \"human_native_1\"\n",
    "#sheet_name = 'Copia di takizawa - Enrico_Evaluation-sheet-jp-v3.0' #  is human_native_2\n",
    "#annotator_id = 'human_native_2'\n",
    "sheet_name = 'tsurusaki_Enrico_Evaluation-sheet-jp-v3.0' #  is human_native_3 tsurusaki_Enrico_Evaluation-sheet-jp-v3.0\n",
    "annotator_id = 'human_native_3'\n",
    "\n",
    "sh = gc.open(sheet_name)\n",
    "# accumulate thing (here maybe add the annotator name)\n",
    "sheet_result = []\n",
    "for sheet_id in range(1,31):\n",
    "    # get sheet\n",
    "    eval_sheet = sh.worksheet(f\"{sheet_id}\")\n",
    "    # get rows\n",
    "    rows = eval_sheet.get_all_values()\n",
    "    # use function\n",
    "    sheet_result += get_block_info_flat(rows)\n",
    "\n",
    "df_gpt4 = pd.DataFrame(sheet_result)\n",
    "\n",
    "df_gpt4['ann_id'] = annotator_id\n",
    "#df_gpt4.to_csv(f\"../../evaluation/annotation/gpt/answers_{annotator_id}.csv\", index=False)\n",
    "df_gpt4.to_csv(f\"../../evaluation/annotation/human/answers_{annotator_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the case of gpt4, we want to look at the agreement between different runs (so the three blocks after the first)\n",
    "\n",
    "sheet_name = 'Evaluation-sheet-jp-v3.0_gpt4'\n",
    "sh = gc.open(sheet_name)\n",
    "# accumulate thing (here maybe add the annotator name)\n",
    "sheet_result = []\n",
    "for sheet_id in range(1,31):\n",
    "    # get sheet\n",
    "    eval_sheet = sh.worksheet(f\"{sheet_id}\")\n",
    "    # get rows\n",
    "    rows = eval_sheet.get_all_values()\n",
    "    time.sleep(20) # because of api request limit\n",
    "    # use function to get the 3 annotations in each sheet (above the first)\n",
    "    for i in range(3):\n",
    "        offset = 20*(i+1)\n",
    "        rows_spec_run = rows[0 + offset:13 + offset]\n",
    "        df_elements = get_block_info_flat(rows_spec_run)\n",
    "\n",
    "        # get a different id here\n",
    "        annotator_id = f'gpt4_{i+1}'\n",
    "        for el in df_elements:\n",
    "            el['ann_id'] = annotator_id\n",
    "        sheet_result += df_elements\n",
    "\n",
    "\n",
    "df_gpt4 = pd.DataFrame(sheet_result)\n",
    "#annotator_id = 'gpt4'\n",
    "#df_gpt4['ann_id'] = annotator_id\n",
    "df_gpt4.to_csv(f\"../../evaluation/annotation/gpt/answers_gpt4_multiple.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4.value_counts(subset=['rank_human'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
