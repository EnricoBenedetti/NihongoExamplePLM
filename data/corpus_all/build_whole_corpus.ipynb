{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have to put together tatoeba, jpWaC and wikipedia into a uniform file.\n",
    "The columns should be: sentence, (diff_level), source, (doc analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import ginza\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico_benedetti/anaconda3/envs/nlp_env/lib/python3.8/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'ja_ginza_electra' (5.1.3) was trained with spaCy v3.2.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('ja_ginza_electra', enable='')\n",
    "nlp.add_pipe('sentencizer')\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_sentences(sentences):\n",
    "    \"\"\"There are rows that contain multiple sentences according to our criteria.\n",
    "    So, to avoid problems, we expand them here. Note that here we lose match with the original dataset.\"\"\"\n",
    "    docs = list(nlp.pipe(sentences))\n",
    "    exp_sentences = []\n",
    "    for doc in docs:\n",
    "        for sent in doc.sents:\n",
    "            exp_sentences.append(sent.as_doc().text)\n",
    "    return exp_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and apply the isgood to tatoeba also\n",
    "def is_good(sentence, token_limit=50, punct_ratio=0.2, numeral_ratio=0.2, tokenizer=None):\n",
    "    \"\"\"Basic surface level requirements for sentence inclusion. requires spacy.\n",
    "    If a list of tokens is passed, the doc is retrieved.\n",
    "    If a sentence is passed, it will be tokenized if also the spacy tokenizer is passed, otherwise it will raise exception...\"\"\"\n",
    "    # based on english characters and urls\n",
    "    # based on having at least 5 tokens [sangawa paper] and ending in punctuation, and ending with a ADJ, VERB, AUX.\n",
    "    \n",
    "    if isinstance(sentence, list):\n",
    "        # retrieve the doc from a list of tokens\n",
    "        sentence = sentence[0].doc\n",
    "    elif isinstance(sentence, str):\n",
    "        sentence = tokenizer(sentence)\n",
    "\n",
    "    sentence_length = len(sentence) # in tokens!!\n",
    "    if sentence_length < 5 or sentence_length > token_limit:\n",
    "        # print('len')\n",
    "        return False\n",
    "    \n",
    "    if (sentence[-1].pos_ != 'PUNCT') or (sentence[-2].pos_ not in ['AUX', 'ADJ', 'VERB']):\n",
    "    # print('ending')\n",
    "        return False\n",
    "    # pattern = r'[a-zA-Z]|https?:\\/\\/\\S+'\n",
    "    # if re.search(pattern, sentence.text) is not None:\n",
    "    #     return False\n",
    "    \n",
    "    # no more than 20% punctuation or numerals\n",
    "    #punct_match = re.findall(r'[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_``{|}~…]', sentence.text)\n",
    "    #punct_count = len(punct_match)\n",
    "    # we do not consider the last\n",
    "    punct_count = sum([token.is_punct for token in sentence[0:-1]])\n",
    "    if punct_count / sentence_length > punct_ratio:\n",
    "        #print('too much punct',sentence_length, punct_count, punct_count / sentence_length)\n",
    "        return False\n",
    "    \n",
    "    # num_match = re.findall(r'\\d', sentence.text)\n",
    "    # num_count = len(num_match)\n",
    "    num_count = sum([token.is_digit for token in sentence]) # digit actually means a full token of digits\n",
    "    if num_count / sentence_length > numeral_ratio:\n",
    "        #print('too much num',sentence_length, punct_count, punct_count / sentence_length)\n",
    "        return False\n",
    "    # no text in other languages\n",
    "    if re.search(r'.*[A-Za-z].*', sentence.text):\n",
    "        # print('english')\n",
    "        return False\n",
    "    \n",
    "    arabic_pattern = r'[\\u0600-\\u06FF\\u0750-\\u077F]+'\n",
    "    if re.search(arabic_pattern, sentence.text):\n",
    "        # print('arabic')\n",
    "        return False\n",
    "\n",
    "    russian_pattern = r'[А-Яа-яЁё]+'\n",
    "    if re.search(russian_pattern, sentence.text):\n",
    "        # print('arabic')\n",
    "        return False\n",
    "\n",
    "\n",
    "    return True\n",
    "\n",
    "def last_filters(sentence):\n",
    "    \"\"\"str based filter to remove outliers from the final dataset\"\"\"\n",
    "    arabic_pattern = r'[\\u0600-\\u06FF\\u0750-\\u077F]+'\n",
    "    if re.search(arabic_pattern, sentence):\n",
    "        # print('arabic')\n",
    "        return False\n",
    "\n",
    "    russian_pattern = r'[А-Яа-яЁё]+'\n",
    "    if re.search(russian_pattern, sentence):\n",
    "        # print('arabic')\n",
    "        return False\n",
    "    \n",
    "    if len(sentence) < 5 or len(sentence) > 100: # in chars!!\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = '../corpus_all/corpus.csv'\n",
    "jpwac_file = '../corpora_original/jpWaC/jpWaC.csv'\n",
    "tatoeba_file = \"../corpora_original/tatoeba/tatoeba.csv\"\n",
    "wikipedia_file = '../corpora_original/wikipedia/wikipedia.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152689\n",
      "152925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>それに伴い、各種問い合わせを受付開始いたします。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>英語とか韓国語、中国語での出版も希望しています。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152920</th>\n",
       "      <td>新しい1年が今，始まろうとしています。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152921</th>\n",
       "      <td>また、どんな言葉をかけたらいいのかも分からなかった。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152922</th>\n",
       "      <td>私も今となってはわかる。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152923</th>\n",
       "      <td>よくわかりますよ。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152924</th>\n",
       "      <td>でも見ません。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152925 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence source   good\n",
       "0       藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。  jpwac   True\n",
       "1               朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。  jpwac  False\n",
       "2           特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。  jpwac   True\n",
       "3                        それに伴い、各種問い合わせを受付開始いたします。  jpwac   True\n",
       "4                        英語とか韓国語、中国語での出版も希望しています。  jpwac   True\n",
       "...                                           ...    ...    ...\n",
       "152920                        新しい1年が今，始まろうとしています。  jpwac   True\n",
       "152921                 また、どんな言葉をかけたらいいのかも分からなかった。  jpwac   True\n",
       "152922                               私も今となってはわかる。  jpwac   True\n",
       "152923                                  よくわかりますよ。  jpwac  False\n",
       "152924                                    でも見ません。  jpwac   True\n",
       "\n",
       "[152925 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpwac_df = pd.read_csv(jpwac_file, usecols=[\"sentence\"])\n",
    "print(len(jpwac_df))\n",
    "jpwac_df = pd.DataFrame({'sentence' : expand_sentences(jpwac_df['sentence'])})\n",
    "print(len(jpwac_df))\n",
    "jpwac_df['source'] = 'jpwac'\n",
    "jpwac_df['good'] = jpwac_df['sentence'].map(lambda s: is_good(s, token_limit=50, tokenizer=tokenizer))\n",
    "jpwac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "True     117960\n",
      "False     34965\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(jpwac_df.good.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239380\n",
      "248522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>きみにちょっとしたものをもってきたよ。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>何かしてみましょう。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>私は眠らなければなりません。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>何してるの？</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>今日は６月１８日で、ムーリエルの誕生日です！</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248517</th>\n",
       "      <td>ワインをお願い。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248518</th>\n",
       "      <td>彼らは私の話を信じようとしなかった。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248519</th>\n",
       "      <td>ハロウィンの仮装だよ。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248520</th>\n",
       "      <td>トムの誕生日に、新しい自転車をプレゼントするんだ。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248521</th>\n",
       "      <td>明日はもっと寒くなるよ。</td>\n",
       "      <td>tatoeba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentence   source   good\n",
       "0             きみにちょっとしたものをもってきたよ。  tatoeba  False\n",
       "1                      何かしてみましょう。  tatoeba   True\n",
       "2                  私は眠らなければなりません。  tatoeba   True\n",
       "3                          何してるの？  tatoeba  False\n",
       "4          今日は６月１８日で、ムーリエルの誕生日です！  tatoeba   True\n",
       "...                           ...      ...    ...\n",
       "248517                   ワインをお願い。  tatoeba  False\n",
       "248518         彼らは私の話を信じようとしなかった。  tatoeba   True\n",
       "248519                ハロウィンの仮装だよ。  tatoeba  False\n",
       "248520  トムの誕生日に、新しい自転車をプレゼントするんだ。  tatoeba   True\n",
       "248521               明日はもっと寒くなるよ。  tatoeba  False\n",
       "\n",
       "[248522 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tatoeba_df = pd.read_csv(tatoeba_file, usecols=[\"sentence\"])\n",
    "# here we expand the sentences\n",
    "print(len(tatoeba_df))\n",
    "tatoeba_df = pd.DataFrame({'sentence' : expand_sentences(tatoeba_df['sentence'])})\n",
    "print(len(tatoeba_df))\n",
    "tatoeba_df['source'] = 'tatoeba'\n",
    "tatoeba_df['good'] = tatoeba_df['sentence'].map(lambda s: is_good(s, token_limit=50, tokenizer=tokenizer))\n",
    "tatoeba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "True     182743\n",
      "False     65779\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tatoeba_df.good.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "# pattern = [\n",
    "#     {\"POS\": {\"in\": [\"VERB\", \"AUX\", \"ADJ\"]}},\n",
    "#     {\"POS\": \"PART\", \"OP\": \"{,2}\"},  # match at most 2 ending particles\n",
    "#     {\"POS\": \"PUNCT\"} \n",
    "#     # no way to easily say end of sentence, but we know that we already split them.\n",
    "# ]\n",
    "# matcher.add(\"sentence_ending\", [pattern])\n",
    "\n",
    "# # doc.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_df = pd.read_csv(wikipedia_file, header=None, names=['sentence'])\n",
    "wikipedia_df['source'] = 'wikipedia'\n",
    "wikipedia_df['good'] = True # assume already analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>アンパサンドの起源は1世紀の古ローマ筆記体にまでさかのぼることができる。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れて...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアン...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語で...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628015</th>\n",
       "      <td>1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628016</th>\n",
       "      <td>1901年8月17日、高等工業学校が追加された。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628017</th>\n",
       "      <td>1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628018</th>\n",
       "      <td>1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628019</th>\n",
       "      <td>カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12628020 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sentence     source  good\n",
       "0                      アンパサンドの起源は1世紀の古ローマ筆記体にまでさかのぼることができる。  wikipedia  True\n",
       "1          それに続く、流麗さを増した新ローマ筆記体では、さまざまな合字が極めて頻繁に使われるようになった。  wikipedia  True\n",
       "2         その後、9世紀のカロリング小文字体に至るラテン文字の変遷の過程で、合字の使用は一般には廃れて...  wikipedia  True\n",
       "3         1455年のヨーロッパにおける印刷技術の発明以降、印刷業者はイタリック体とローマ筆記体のアン...  wikipedia  True\n",
       "4         アンパサンドのルーツはローマ時代にさかのぼるため、ラテンアルファベットを使用する多くの言語で...  wikipedia  True\n",
       "...                                                     ...        ...   ...\n",
       "12628015               1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。  wikipedia  True\n",
       "12628016                           1901年8月17日、高等工業学校が追加された。  wikipedia  True\n",
       "12628017                 1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。  wikipedia  True\n",
       "12628018       1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。  wikipedia  True\n",
       "12628019                   カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。  wikipedia  True\n",
       "\n",
       "[12628020 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then,\n",
    "# 0 merge all of them\n",
    "df = pd.concat([jpwac_df, tatoeba_df, wikipedia_df], ignore_index=True)\n",
    "# 1 remove duplicates\n",
    "df_no_dup = df\n",
    "sent_no_dup = df['sentence'].drop_duplicates()\n",
    "df_no_dup['sentence'] = sent_no_dup\n",
    "df_no_dup = df_no_dup.dropna(axis='index', how='any')\n",
    "\n",
    "# 1.5 apply isgood filter? yes but no discard\n",
    "#df_all_good = df_no_dup[df_no_dup['good']]\n",
    "# 2 reset index / shuffle??\n",
    "#df_all_good = df_all_good.reset_index(drop=True)\n",
    "# 3 save as corpus.csv\n",
    "#df_all_good.to_csv(out_file, columns=['sentence', 'source'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate - save also the bad part... but bad sentences will still be used, I think.\n",
    "df_all = df_no_dup.reset_index(drop=True)\n",
    "filtered = df_all['sentence'].apply(last_filters)\n",
    "df_all = df_all[filtered]\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "df_all.to_csv(out_file, columns=['sentence', 'source', 'good'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its better to save only the sentences and put the indeces in readme or other file...\n",
    "# we save 200MB\n",
    "df_all.to_csv(out_file, columns=['sentence'], index=False)\n",
    "first_unique_index = df_all[df_all['source'].duplicated() == False].index\n",
    "df_all['source'].loc[first_unique_index].to_csv('sources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>source</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>それに伴い、各種問い合わせを受付開始いたします。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>英語とか韓国語、中国語での出版も希望しています。</td>\n",
       "      <td>jpwac</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704955</th>\n",
       "      <td>1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704956</th>\n",
       "      <td>1901年8月17日、高等工業学校が追加された。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704957</th>\n",
       "      <td>1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704958</th>\n",
       "      <td>1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704959</th>\n",
       "      <td>カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704960 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence     source   good\n",
       "0            藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。      jpwac   True\n",
       "1                    朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。      jpwac  False\n",
       "2                特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。      jpwac   True\n",
       "3                             それに伴い、各種問い合わせを受付開始いたします。      jpwac   True\n",
       "4                             英語とか韓国語、中国語での出版も希望しています。      jpwac   True\n",
       "...                                                ...        ...    ...\n",
       "12704955          1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。  wikipedia   True\n",
       "12704956                      1901年8月17日、高等工業学校が追加された。  wikipedia   True\n",
       "12704957            1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。  wikipedia   True\n",
       "12704958  1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。  wikipedia   True\n",
       "12704959              カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。  wikipedia   True\n",
       "\n",
       "[12704960 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence  source  good \n",
       "False     False   False    12704960\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>それに伴い、各種問い合わせを受付開始いたします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>英語とか韓国語、中国語での出版も希望しています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704955</th>\n",
       "      <td>1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704956</th>\n",
       "      <td>1901年8月17日、高等工業学校が追加された。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704957</th>\n",
       "      <td>1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704958</th>\n",
       "      <td>1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12704959</th>\n",
       "      <td>カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704960 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "0            藤井氏の著書の販売から、ここでしか買えない音声メールマガジンのコーナーもあります。\n",
       "1                    朱肉のつけすぎは、他人に写し取られて悪用されかねませんので、注意。\n",
       "2                特にこれに関して習得したいと思われるテーマがあれば気軽にリクエスト下さい。\n",
       "3                             それに伴い、各種問い合わせを受付開始いたします。\n",
       "4                             英語とか韓国語、中国語での出版も希望しています。\n",
       "...                                                ...\n",
       "12704955          1883年9月4日、道路、運河、港湾、鉱山に関する学校として設立された。\n",
       "12704956                      1901年8月17日、高等工業学校が追加された。\n",
       "12704957            1975年にはムルシア大学に組み込まれてカルタヘナ工科学校となった。\n",
       "12704958  1998年8月3日にムルシア大学から分離され、大学としてのカルタヘナ工科大学が開学した。\n",
       "12704959              カルタヘナ工科大学はカルタヘナ都市圏に3キャンパスを有している。\n",
       "\n",
       "[12704960 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_test = pd.read_csv(out_file)\n",
    "read_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
